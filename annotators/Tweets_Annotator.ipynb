{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Zagreb<br>\n",
    "Faculty of Electrical Engineering and Computing\n",
    "\n",
    "# Text Analysis and Retrieval (TAR)\n",
    "\n",
    "<a href=\"http://www.fer.unizg.hr/predmet/apt\">http://www.fer.unizg.hr/predmet/apt</a>\n",
    "\n",
    "2015./2016.\n",
    "\n",
    "# Project theme 13: Tweet classification\n",
    "\n",
    "\n",
    "(c) 2016 Group nedovrs: Tomislav Marinković, Josip Milić, Domagoj Pereglin\n",
    "\n",
    "*Version 0.95*\n",
    "\n",
    "Date: **05.06.2016.**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tweets dataset annotator</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Packages:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re # za regularni izraz ()\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tweet classes (categories):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_categories = {}\n",
    "tweet_categories[2] = 'DEALS'\n",
    "tweet_categories[3] = 'NEWS_TECHNOLOGY'\n",
    "tweet_categories[4] = 'NEWS_POLITICS'\n",
    "tweet_categories[5] = 'NEWS_SPORT'\n",
    "tweet_categories[6] = 'NEWS_REST'\n",
    "tweet_categories[7] = 'REST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wanted tweets dataset:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_dir_path = r'..\\datasets'\n",
    "dataset_file_name = 'hrtsport_tweets.txt'\n",
    "annotated_tweets_file_path = r'..\\annotations\\annotations_' + dataset_file_name.replace('.txt','.csv')\n",
    "dataset_path = dataset_dir_path +'\\\\'+ dataset_file_name\n",
    "dataset_file = codecs.open(dataset_path, 'r', 'utf-8')\n",
    "dataset = []\n",
    "for line in dataset_file:\n",
    "    dataset.append(line.split('|', 2))\n",
    "dataset_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Annotation file creation:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_categories():\n",
    "    for i in sorted(tweet_categories):\n",
    "        print i,'-',tweet_categories[i]\n",
    "    print ''\n",
    "\n",
    "\n",
    "def create_open_annotated_file():\n",
    "    try :\n",
    "        annotated_tweets_file =  open(annotated_tweets_file_path,'r')\n",
    "    except:\n",
    "        annotated_tweets_file = open(annotated_tweets_file_path,'w+')\n",
    "    annotated_tweets = [x.split(';')[1] for x in annotated_tweets_file]\n",
    "    annotated_tweets_file.close()\n",
    "    print 'Broj prethodnih anotacija: %d\\n' % len(annotated_tweets)\n",
    "    return annotated_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tweet dataset annotation:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "presentation_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - DEALS\n",
      "3 - NEWS_TECHNOLOGY\n",
      "4 - NEWS_POLITICS\n",
      "5 - NEWS_SPORT\n",
      "6 - NEWS_REST\n",
      "7 - REST\n",
      "\n",
      "@hrtsport 717808889421541381\n",
      "Mamić nakon @hajduk:  Jako sam sretan i zadovoljan zbog visoke pobjede.  http://bit.ly/1XhFjM1 http://pbs.twimg.com/media/CfYrYYgXIAADjb0.jpg\n",
      "Kategorija? 5\n",
      "\n",
      "\n",
      "\n",
      "@hrtsport 717802920373272577\n",
      "Izvrsni Ante Žižić upisao 26 poena i 24 skoka u pobjedi @kk_cibona u Šibeniku  http://bit.ly/1PUzQVq http://pbs.twimg.com/media/CfYl870WQAAlEqD.jpg\n",
      "Kategorija? fgfg\n",
      "Ukupno novih anotacija: 2\n"
     ]
    }
   ],
   "source": [
    "print_categories()\n",
    "annotated_tweets = create_open_annotated_file()\n",
    "default_category = 5 # ako se kao input pritisne enter, stavit će defaultnu kategoriju, procijenite koja bi to bila\n",
    "tweet_user = dataset_file_name.replace('_tweets.txt','')\n",
    "fresh_annotations = []\n",
    "clear_switch = False\n",
    "for tweet in dataset:\n",
    "    tweet_id = tweet[0]\n",
    "    if tweet_id in annotated_tweets:\n",
    "        continue\n",
    "    tweet_text = tweet[2].rstrip()\n",
    "    print '@'+tweet_user, tweet_id\n",
    "    print tweet_text\n",
    "    tweet_category_str = raw_input('Kategorija? ')\n",
    "    try:\n",
    "        tweet_category = int(tweet_category_str)\n",
    "        if tweet_category not in tweet_categories:\n",
    "            break # ako je input broj koji nije među kategorijama onda prekida anotiranje\n",
    "        fresh_annotations.append((tweet_id,tweet_category))\n",
    "    except:\n",
    "        if tweet_category_str == '':\n",
    "            tweet_category = default_category\n",
    "            fresh_annotations.append((tweet_id,tweet_category))\n",
    "            print tweet_category\n",
    "        else:\n",
    "            break # ako je input nešto što nije broj onda prekida anotiranje\n",
    "    if (clear_switch):\n",
    "        clear_output()\n",
    "        print_categories()\n",
    "        print '@'+tweet_user, tweet_id\n",
    "        print tweet_text.rstrip()\n",
    "        print 'Kategorija? %d' % tweet_category\n",
    "        clear_switch = False\n",
    "    else:\n",
    "        clear_switch = True\n",
    "    print '\\n\\n'\n",
    "print 'Ukupno novih anotacija: %d' % len(fresh_annotations)\n",
    "if not presentation_mode:\n",
    "    annotated_tweets_file =  open(annotated_tweets_file_path,'a+')\n",
    "    for (tweet_id,tweet_category) in fresh_annotations:\n",
    "        annotated_tweets_file.write('%s;%s;%d\\n' % (tweet_user,tweet_id,tweet_category))\n",
    "    annotated_tweets_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Number of annotations (all datasets)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - DEALS = 976 anotacija\n",
      "3 - NEWS_TECHNOLOGY = 1043 anotacija\n",
      "4 - NEWS_POLITICS = 1657 anotacija\n",
      "5 - NEWS_SPORT = 1052 anotacija\n",
      "6 - NEWS_REST = 2738 anotacija\n",
      "7 - REST = 3257 anotacija\n",
      "\n",
      "Sum od annotations: 10723\n"
     ]
    }
   ],
   "source": [
    "tweet_categories_annotated = dict(zip(tweet_categories.keys(),[0]*len(tweet_categories)))\n",
    "\n",
    "annotations_dir = r'..\\annotations'\n",
    "for annotations_name in os.listdir(annotations_dir):\n",
    "    if '.csv' in annotations_name:\n",
    "        annotated_tweets_file = open(annotations_dir + '\\\\'  + annotations_name ,'r')\n",
    "        for line in annotated_tweets_file:\n",
    "            tweet_category = int(line.split(';')[-1])\n",
    "            tweet_categories_annotated[tweet_category] += 1\n",
    "for tweet_category in sorted(tweet_categories_annotated):\n",
    "    print '%d - %s = %d anotacija' % (tweet_category, tweet_categories[tweet_category], tweet_categories_annotated[tweet_category])\n",
    "print '\\nSum od annotations: %d' % (sum(tweet_categories_annotated.values()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Annotated tweet text retrieval:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@bugonline\n",
      "GeForce 1080 i 1070 samo u jednoj verziji: http://is.gd/ldL8lT ^tj\n",
      "\n",
      "Category: NEWS_TECHNOLOGY\n",
      "Tweet link: https://twitter.com/anyuser/status/729438412105760769\n"
     ]
    }
   ],
   "source": [
    "annotation_test = 'bugonline;729438412105760769;3'\n",
    "\n",
    "dataset_test,tweet_id_test,tweet_category_test = annotation_test.split(';')\n",
    "tweet_category_test = int(tweet_category_test)\n",
    "dataset_file_test = open(dataset_dir_path + '\\\\' + dataset_test + '_tweets.txt','r')\n",
    "for line in dataset_file_test:\n",
    "    if tweet_id_test == line.split('|',2)[0]:\n",
    "        print '@' + dataset_test\n",
    "        print line.split('|',2)[2]\n",
    "        print 'Category: %s' % tweet_categories[tweet_category_test]\n",
    "        print 'Tweet link: https://twitter.com/anyuser/status/%s' % tweet_id_test\n",
    "        break\n",
    "dataset_file_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cohen's kappa:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between annotators Domagoj and Josip: 0.804860, po = 0.843333, pe = 0.197156\n",
      "Cohen's kappa between annotators Domagoj and Tomislav: 0.745533, po = 0.793333, pe = 0.187844\n",
      "Cohen's kappa between annotators Josip and Tomislav: 0.741521, po = 0.790000, pe = 0.187556\n",
      "\n",
      "Average Cohen's kappa: 0.763971, po = 0.808889, pe = 0.190852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "kappa_annotations_dir_path = r'..\\kappa_annotations'\n",
    "keys = []\n",
    "kappa_annotations = {}\n",
    "for kappa_annotations_dir in os.listdir(kappa_annotations_dir_path):\n",
    "    annotator_name = kappa_annotations_dir.replace('.csv','').split('_')[-1]\n",
    "    key_values = [] \n",
    "    for kappa_annotations_file_name in os.listdir(kappa_annotations_dir_path+'\\\\'+kappa_annotations_dir):\n",
    "        key_values += [tuple(x.rstrip().split(';')[1:]) for x in open(kappa_annotations_dir_path+'\\\\'+kappa_annotations_dir+'\\\\'+kappa_annotations_file_name,'r').readlines()]\n",
    "        \n",
    "    kappa_annotations[annotator_name] = dict(key_values)\n",
    "    if keys == []:\n",
    "        keys = kappa_annotations[annotator_name].keys()\n",
    "kappa_dict = {}\n",
    "annotator_names = sorted(kappa_annotations)\n",
    "y = []\n",
    "for key in keys:\n",
    "    kappa_dict[key] = []\n",
    "    for annotator_name in annotator_names:\n",
    "        kappa_dict[key].append(int(kappa_annotations[annotator_name][key]))\n",
    "    y.append(kappa_dict[key])\n",
    "        \n",
    "\n",
    "num_of_annotators = len(y[0])\n",
    "indices_combinations = []\n",
    "for i in range(num_of_annotators-1):\n",
    "    for j in range(i+1,num_of_annotators):\n",
    "        indices_combinations.append((i,j))\n",
    "indices_combinations\n",
    "\n",
    "kappa = 0.0\n",
    "po = 0.0\n",
    "pe = 0.0\n",
    "for indices in indices_combinations:\n",
    "    i,j = indices\n",
    "    y1 = [x[i] for x in y]\n",
    "    y2 = [x[j] for x in y]\n",
    "    confusion = confusion_matrix(y1, y2)\n",
    "    P = confusion / float(confusion.sum())\n",
    "    p_observed = np.trace(P)\n",
    "    p_expected = np.dot(P.sum(axis=0), P.sum(axis=1))\n",
    "    kappa_current = (p_observed - p_expected) / (1 - p_expected)\n",
    "    print 'Cohen\\'s kappa between annotators %s and %s: %f, po = %f, pe = %f' % (annotator_names[i],annotator_names[j],kappa_current, p_observed, p_expected)\n",
    "    kappa += kappa_current\n",
    "    po += p_observed\n",
    "    pe += p_expected\n",
    "kappa /= len(indices_combinations)\n",
    "po /= len(indices_combinations)\n",
    "pe /= len(indices_combinations)\n",
    "\n",
    "print ''\n",
    "print 'Average Cohen\\'s kappa: %f, po = %f, pe = %f' % (kappa,po,pe)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
